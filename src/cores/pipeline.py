# -*- coding: utf-8 -*-
"""
@Time    : 2025/4/23
@Author  : å•é‘«
@File    : qa_pipeline.py
@Desc    : æ”¯æŒé…ç½®åŒ–ã€æ‰¹é‡é—®ç­”ã€è‡ªåŠ¨è¯„ä¼°ã€æ¥å£è°ƒç”¨çš„çŸ¥è¯†åº“é—®ç­”æ¨¡å—å°è£…
"""
from src.models.embedding import TextEmbedding
from src.db_services.milvus.connection_manager import MilvusConnectionManager
from src.agent.memory import ConversationMemory
from src.models.llm import LLMWrapper
from src.evaluate.evaluate import QAEvaluator
from src.evaluate.rag import RAGASEvaluator
from src.cores.message_builder import MessageBuilder
from src.configs.config import AppConfig
from src.configs.retrieve_config import SearchConfig
from src.cores.query_transformer import QueryTransformer
from src.configs.logger_config import setup_logger
from src.mcp.mcp_client import MCPClient, mcp_main
from src.utils.prompt import PromptManager

from langchain_text_splitters import RecursiveCharacterTextSplitter
from typing import List, Dict
import asyncio
from langfuse import get_client, observe

logger = setup_logger(__name__)

from typing import Optional


class QAPipeline:
    def __init__(self, config: AppConfig, langfuse_client: Optional[get_client] = None):
        self.logger = logger
        self.config = config
        self.langfuse_client = langfuse_client
        self._init_components()

        self.logger.info("QAPipeline åˆå§‹åŒ–å®Œæˆ")

    def _init_components(self):
        self.logger.info("åˆå§‹åŒ– QAPipeline...")

        self.logger.info("åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥æ¨¡å‹...")
        self.embeddings = TextEmbedding(self.config.embedding)

        self.logger.info("åˆå§‹åŒ– LLM åŒ…è£…å™¨...")
        self.llm_caller = LLMWrapper(self.config.llm)

        self.logger.info("åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨...")
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.splitter.chunk_size,
            chunk_overlap=self.config.splitter.chunk_overlap
        )

        self.logger.info("åˆå§‹åŒ–æ¶ˆæ¯æ„å»ºå™¨...")
        self.message_builder = MessageBuilder(self.config.message_builder)

        self.logger.info("åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç®¡ç†å™¨...")
        # ä½¿ç”¨ç»Ÿä¸€çš„ MilvusDB å…¥å£ç±»
        self.db_connection_manager = MilvusConnectionManager(self.embeddings, self.text_splitter, self.config.milvus,
                                                             self.config.retrieve)

        self.logger.info("åˆå§‹åŒ–å¯¹è¯è®°å¿†...")
        self.memory = ConversationMemory(self.config.retrieve)
        self.logger.info("åˆå§‹åŒ– MCP å®¢æˆ·ç«¯...")
        self.mcp_client = MCPClient(self.llm_caller)

        self.logger.info("åˆå§‹åŒ–è¯„ä¼°å™¨...")
        self.evaluator = QAEvaluator(self, self.config.evaluation, self.config.retrieve)
        self.ragas_evaluator = RAGASEvaluator(config=self.config.evaluation)
        self.logger.info("åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨...")
        self.logger.info("åˆå§‹åŒ–æŸ¥è¯¢è½¬æ¢å™¨...")
        self.query_transformer = QueryTransformer(self.llm_caller, self.message_builder, self.embeddings,
                                                  self.db_connection_manager, self.config.rewrite)
        # åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯
        self.logger.info("åˆå§‹åŒ– Langfuse ...")
        self.logger.info("åˆå§‹åŒ– prompt manager")
        self.prompt_manager = PromptManager(self.langfuse_client)

    @observe(name="QAPipline.build_knowledge_base")
    async def build_knowledge_base(self, data_dir: str):
        self.logger.info(f"å¼€å§‹æ„å»ºçŸ¥è¯†åº“ï¼Œæ•°æ®ç›®å½•: {data_dir}")
        await self.db_connection_manager.add_documents_from_dir(data_dir)
        self.logger.info("çŸ¥è¯†åº“æ„å»ºå®Œæˆ")

    @observe(name="QAPipeline._build_messages")
    async def _build_messages(self, query):
        system_prompt = self.prompt_manager.get_prompt(
            "kb_system_prompt") if self.config.retrieve.use_kb else self.prompt_manager.get_prompt("system_prompt")

        context, _ = await self._prepare_context(query)
        messages = self.message_builder.build(
            query=query,
            context=context,
            use_memory=self.config.retrieve.use_memory,
            memory_items=list(self.memory.memory) if self.config.retrieve.use_memory else [],
            system_prompt_template=system_prompt,
            no_think=self.config.retrieve.no_think,
            max_tokens=self.config.message_builder.message_max_tokens,
            max_history_turns=self.config.retrieve.memory_window_size
        )
        return messages, context

    async def _retrieve_kb_context(self, query: str) -> tuple[str, str]:
        """
        æ‰§è¡ŒçŸ¥è¯†åº“æ£€ç´¢ï¼Œè¿”å›æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å’ŒåŸå§‹æ£€ç´¢å†…å®¹ã€‚
        å¦‚æœé…ç½®æœªå¼€å¯çŸ¥è¯†åº“ï¼Œè¿”å›ç©ºå…ƒç»„ã€‚
        """
        retrieve_config = self.config.retrieve
        if not retrieve_config.use_kb:
            return "", ""

        self.logger.info("ğŸŸ¢ å¼€å§‹çŸ¥è¯†åº“æ£€ç´¢")

        # ç¡®å®šå¹¶æ‰§è¡Œæ£€ç´¢é€»è¾‘
        use_hyde = retrieve_config.use_rewrite and retrieve_config.rewrite_mode == 'hyde'

        if use_hyde:
            results = await self.query_transformer.hyde_search(query, retrieve_config)
        else:
            results = await self.db_connection_manager.asearch(query, retrieve_config)

        # å¤„ç†æ£€ç´¢ç»“æœ
        if results and results[0]:
            kb_context_docs = "\n".join([f"ã€æ–‡æ¡£{i + 1}ã€‘{doc.get('text', 'å†…å®¹ç¼ºå¤±')}"
                                         for i, doc in enumerate(results)])
            return f"ã€çŸ¥è¯†åº“æ£€ç´¢å†…å®¹ã€‘\n{kb_context_docs}", kb_context_docs
        else:
            return "ã€çŸ¥è¯†åº“æ£€ç´¢å†…å®¹ã€‘\næœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†ã€‚", ""

    async def _retrieve_tool_context(self, query: str) -> str:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œå¹¶è¿”å›æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ã€‚
        å¦‚æœé…ç½®æœªå¼€å¯å·¥å…·ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
        """
        if not self.config.retrieve.use_tool:
            return ""
        try:
            tool_result = await mcp_main(self.mcp_client, query)
        except Exception as e:
            self.logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            return ""

        if tool_result:
            self.logger.debug(f"âœ… å·¥å…·è¿”å›å†…å®¹é•¿åº¦: {len(tool_result)}")
            return f"ã€å·¥å…·è¿”å›å†…å®¹ã€‘\n{tool_result}"

        return ""

    @observe(name="QAPipline._prepare_context")
    async def _prepare_context(self, query) -> (str, str):
        context_blocks = []
        # --- Step 1: å·¥å…·è°ƒç”¨ ---
        tool_formatted_context = await self._retrieve_tool_context(query)
        tool_context_raw = ""
        if tool_formatted_context:
            context_blocks.append(tool_formatted_context)
            tool_context_raw = tool_formatted_context.split('\n', 1)[-1]

        # --- Step 2: çŸ¥è¯†åº“æ£€ç´¢ ---
        kb_formatted_context, kb_context_raw = await self._retrieve_kb_context(query)
        if kb_formatted_context:
            context_blocks.append(kb_formatted_context)

        # --- Step 3: ç»“æœç»„è£… ---
        final_context = "\n\n".join(context_blocks)
        summary_context = kb_context_raw or tool_context_raw
        return final_context, summary_context

    @observe(name="QAPipline.ask", as_type="chain")
    async def ask(self, query: str, config: SearchConfig = None) -> Dict:

        if config:
            self.config.retrieve = config

        if self.config.retrieve.session_id:
            self.logger.info(
                f"æ›´æ–°å½“å‰è¿½è¸ªç”¨æˆ·åŠä¼šè¯ID: {self.config.retrieve.user_id}, {self.config.retrieve.session_id}")
            self.langfuse_client.update_current_trace(user_id=self.config.retrieve.user_id,
                                                      session_id=self.config.retrieve.session_id)

        self.logger.info(f"æ”¶åˆ°é—®é¢˜: {query}")
        if not query.strip():
            self.logger.error("é—®é¢˜ä¸èƒ½ä¸ºç©º")
            return {"error": "é—®é¢˜ä¸èƒ½ä¸ºç©º"}

        try:
            if self.config.retrieve.use_rewrite and self.config.retrieve.rewrite_mode != "hyde":
                self.logger.info(f"ä½¿ç”¨ {self.config.retrieve.rewrite_mode} æ¨¡å¼é‡å†™æŸ¥è¯¢")
                query = self.query_transformer.transform_query(query, self.config.retrieve.rewrite_mode)

            self.logger.debug(
                f"æŸ¥è¯¢å‚æ•°: k={self.config.retrieve.top_k}, use_sparse={self.config.retrieve.use_sparse}, use_reranker={self.config.retrieve.use_reranker}")
            messages, context = await self._build_messages(query)
            self.logger.info("å¼€å§‹è°ƒç”¨ LLM ç”Ÿæˆå›ç­”")
            answer = await self.llm_caller.achat(messages)
            self.logger.info("LLM å›ç­”ç”Ÿæˆå®Œæˆ")

            if self.config.retrieve.use_memory:
                self.logger.debug("æ›´æ–°å¯¹è¯è®°å¿†")
                self.memory.add(query, answer)

            return {"question": query, "answer": answer, "context": context}
        except Exception as e:
            self.logger.exception("å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸")
            return {"error": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"}

    @observe(name="QAPipline.ask_stream")
    async def ask_stream(self, query: str, config: SearchConfig = None):

        if config:
            self.config.retrieve = config
        self.logger.info(f"æ”¶åˆ°æµå¼é—®é¢˜: {query}")
        if not query.strip():
            self.logger.error("é—®é¢˜ä¸èƒ½ä¸ºç©º")
            yield {"error": "é—®é¢˜ä¸èƒ½ä¸ºç©º"}
            return

        try:
            if self.config.retrieve.use_rewrite:
                self.logger.info(f"ä½¿ç”¨ {self.config.retrieve.rewrite_mode} æ¨¡å¼é‡å†™æŸ¥è¯¢")
                query = self.query_transformer.transform_query(query, self.config.retrieve.rewrite_mode)

            self.logger.debug(
                f"æµå¼æŸ¥è¯¢å‚æ•°: k={self.config.retrieve.top_k}, use_sparse={self.config.retrieve.use_sparse}, use_reranker={self.config.retrieve.use_reranker}")
            messages, context = await self._build_messages(query)
            self.logger.info("å¼€å§‹æµå¼è°ƒç”¨ LLM")
            stream = await self.llm_caller.achat(messages, stream=True)
            answer = ""
            async for chunk in stream:
                delta = getattr(chunk.choices[0].delta, 'content', None)
                if delta:
                    answer += delta
                    yield {"delta": delta}

            self.logger.info("æµå¼å›ç­”ç”Ÿæˆå®Œæˆ")
            if self.config.retrieve.use_memory:
                self.logger.debug("æ›´æ–°å¯¹è¯è®°å¿†")
                self.memory.add(query, answer)

        except Exception as e:
            self.logger.exception("å¤„ç†æµå¼è¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸")
            yield {"error": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"}

    @observe(name="QAPipline.batch_ask")
    async def batch_ask(self, questions: List[str]) -> List[Dict]:
        self.logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(questions)} ä¸ªé—®é¢˜")
        # åˆ›å»ºä¸€ç³»åˆ—å¼‚æ­¥ä»»åŠ¡
        tasks = [self.ask(q) for q in questions]
        # ä½¿ç”¨ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks)
        self.logger.info("æ‰¹é‡å¤„ç†å®Œæˆ")
        return results

    @observe(name="QAPipline.evaluate")
    async def evaluate(self, qa_pairs):
        """
        è¯„ä¼°é—®ç­”å¯¹
        
        Args:
            qa_pairs: é—®ç­”å¯¹åˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹è¯„ä¼°ï¼Œä½¿ç”¨ {self.config.evaluation.eval_method} æ–¹æ³•")

        if self.config.evaluation.eval_method == "ragas":
            self.logger.info("ä½¿ç”¨ RAGAS è¯„ä¼°æ–¹æ³•")

            # å‡†å¤‡ RAGAS è¯„ä¼°æ•°æ®
            async def run_and_format_ask(pair):
                """å†…éƒ¨å¼‚æ­¥å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œ ask å¹¶æ ¼å¼åŒ– RAGAS éœ€è¦çš„æ•°æ®"""
                result = await self.ask(pair["question"])
                return {
                    "query": pair["question"],
                    "prediction": result["answer"],
                    # ä½¿ç”¨ get() å¢åŠ å¥å£®æ€§ï¼Œé˜²æ­¢ context ä¸º None
                    "contexts": result.get("context", "").split("\n") if result.get("context") else [],
                    "ground_truths": [pair["answer"]]
                }

            # ä½¿ç”¨ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰é—®ç­”ä»»åŠ¡
            tasks = [run_and_format_ask(pair) for pair in qa_pairs]
            qa_data = await asyncio.gather(*tasks)
            # æ‰§è¡Œ RAGAS è¯„ä¼°
            results = self.ragas_evaluator.evaluate(qa_data)
            self.logger.info("RAGAS è¯„ä¼°å®Œæˆ")
            return results
        else:
            # ä½¿ç”¨åŸæœ‰è¯„ä¼°æ–¹æ³•
            results = self.evaluator.evaluate(qa_pairs=qa_pairs)
            self.logger.info("è¯„ä¼°å®Œæˆ")
            return results

    @observe(name="QAPipline.clear_memory")
    def clear_memory(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.logger.info("æ¸…é™¤å¯¹è¯è®°å¿†")
        self.memory.clear()
